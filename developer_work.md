[Back to home](https://venkatvv.github.io/)

# Overview 

I created a data pipeline for the Professor Z. Morley Mao over the summer of 2016. It was created by utilizing Apache Kafka (a distributed streaming platform) and Apache Hadoop (a framework that allows for the distributed processing of large data sets across clusters of computers). The data is then displayed visually through Grafana (a time series database) and shown in real-time.

This presentation below provides a brief overview of my work for the University of Michigan.

<iframe id="iframe_container" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen="" width="100%" height="510" src="https://prezi.com/embed/4zdlawrgpltz/?bgcolor=ffffff&amp;lock_to_path=0&amp;autoplay=0&amp;autohide_ctrls=0&amp;landing_data=bHVZZmNaNDBIWnNjdEVENDRhZDFNZGNIUE43MHdLNWpsdFJLb2ZHanI5bHdQaWVXZ0ZUdG5Bb3JTbk9HL3JNbTN3PT0&amp;landing_sign=mdX47eiGRdRTVxFZVnMsyUjb29DJcnPT3cJ3kq0iHDc"></iframe>

# My Contributions and Experience 

Comming into this job I had very little experience with java and very little experience dealing with APIs.